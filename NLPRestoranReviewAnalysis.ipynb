{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN1i1XvanLRZKOuoTXhj8hy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aekaba/RestoranReviewsNLP/blob/main/NLPRestoranReviewAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDİ Ödev 2 Soru 2\n",
        "## Derlem Özellikleri\n",
        "Seçtiğim derlem http://metashare.ilsp.gr:8080/repository/browse/semeval-2016-absa-restaurant-reviews-turkish-train-data-subtask-1/ff5dad70676311e5bf9c842b2b6a04d71fa7fa3ba4504a228dafe0c24560585b/\n",
        "içinde 320 cümle bulunduruyo, bunlar 2016 yılının restoran geri dönüşlerini içeren cümleler ve 1232 kelime bulunan bir derlem oluşturulmuştur. Veriler bir xml dosyası içerisinde tutulmaktadır.\n",
        "## Çalışmanın Hedefi\n",
        "Çalışma, hem hedef alan hemde duygu analizi içeren bir model geliştirmek. Böylelikle geliştirilen model, restoranların hangi alanlarının iyi olduğunu hangi alanlarının kötü olduğunu belirtebilmektedir.\n",
        "## Yöntem\n",
        "Çalışma Google Colab üzerinde geliştirilmiştir. Bir python not defteri oluşturularak her adım üzerinde açıklama yapılarak anlatılmıştır. Bir python kütüphanesi olan nltk kullanarak doğal dil işleme adımları yapılmıştır. Model Naive bayes makine öğrenme modeli kullanılarak geliştirilmiştir. Veri okuma ve ön işleme aşamaları pandas kütüphanesi ile gerçekleştirilmiştir.\n",
        "1. Veri Okuma ve Data Frame oluşturma  \n",
        "  python xml kütüphanesi ile google colab'a yüklediğimiz xml dosyasını açıp, satır satır okuyoruz. İçindeki hali hazırda etiketlenmiş verileri bir dataframe e aktarıyoruz.\n",
        "  Verilerimiz Text - Target - Category - Polarity olmak üzere 4 sütuna ayrılmıştır.  \n",
        "  Text: Cümlenin kendisi.   \n",
        "  Target: Yorumu ilgilendiren bölüm.  \n",
        "  Category: Metinde bahsedilen hedefin nasıl daha geniş bir sınıfa dahil olduğunu belirtir.  \n",
        "  Polarity: Metnin duygusunu belirten kısım.  \n",
        "  bir cümlenin birden fazla görüşü olabilir.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OaJkXYl1F3HW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmEtXs3dFyrF",
        "outputId": "560d55c3-5a0d-43f6-95a8-7024ca3c17dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text     target  \\\n",
            "0            Manzara sahane evet ama servis rezalet.     servis   \n",
            "1            Manzara sahane evet ama servis rezalet.    Manzara   \n",
            "2  Soguk su isteyince, soguk yok, butun sulari di...    mezenin   \n",
            "3  Soguk su isteyince, soguk yok, butun sulari di...     garson   \n",
            "4  Yemekler iyi hos, lezzetler iyi ama heyecan ve...  lezzetler   \n",
            "\n",
            "             category  polarity  \n",
            "0     SERVICE#GENERAL  negative  \n",
            "1    AMBIENCE#GENERAL  positive  \n",
            "2  FOOD#STYLE_OPTIONS  negative  \n",
            "3     SERVICE#GENERAL  negative  \n",
            "4        FOOD#QUALITY  positive  \n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# XML dosyasını okuma\n",
        "tree = ET.parse('/content/reviews.xml')  # Derlem Dosyamız\n",
        "root = tree.getroot()\n",
        "\n",
        "data = []\n",
        "\n",
        "for review in root.findall(\"Review\"):\n",
        "    for sentence in review.find(\"sentences\").findall(\"sentence\"):\n",
        "        if \"OutOfScope\" not in sentence.attrib:\n",
        "            text = sentence.find(\"text\").text\n",
        "            opinions = sentence.find(\"Opinions\")\n",
        "            if opinions is not None:\n",
        "                for opinion in opinions.findall(\"Opinion\"):\n",
        "                    target = opinion.attrib[\"target\"]\n",
        "                    category = opinion.attrib[\"category\"]\n",
        "                    polarity = opinion.attrib[\"polarity\"]\n",
        "                    data.append({\"text\": text, \"target\": target, \"category\": category, \"polarity\": polarity})\n",
        "\n",
        "# DataFrame oluşturma\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Veri Ön İşleme  \n",
        "  Burada oluşturulan dataframe içinde bulunan metin kısmının temizlenmesi gerekmektedir. Noktalama işaretleri kaldırlıcak ve tüm metinler küçük harflere dönüştürülecektir. Sonrasında temizlenmiş veri yeni bir stün olarak eklenecektir. Sonrasında algoritmamızın alnayabilmesi için kategori ve hedef kısmını sayısal verilere çevirmemiz gerekecektir. Her biri sayısal olarak etiketlenip dataframe de yeni bir sütun a atanacaktır.\n"
      ],
      "metadata": {
        "id": "zKVmPMK1TPhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "turkish_stop_words = stopwords.words('turkish')\n",
        "# Metin temizleme\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Noktalama işaretlerini kaldır\n",
        "    text = text.lower()  # Küçük harfe dönüştür\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Etiketleme\n",
        "le_category = LabelEncoder()\n",
        "le_polarity = LabelEncoder()\n",
        "\n",
        "df['category_label'] = le_category.fit_transform(df['category'])\n",
        "df['polarity_label'] = le_polarity.fit_transform(df['polarity'])\n",
        "\n",
        "print(\"Kategori Etiketleri:\", dict(zip(le_category.classes_, le_category.transform(le_category.classes_))))\n",
        "print(\"Duygu Etiketleri:\", dict(zip(le_polarity.classes_, le_polarity.transform(le_polarity.classes_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdy3UWUYNPa7",
        "outputId": "2a745679-18b0-415f-a744-f4028acae318"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kategori Etiketleri: {'AMBIENCE#GENERAL': 0, 'DRINKS#PRICES': 1, 'DRINKS#QUALITY': 2, 'DRINKS#STYLE_OPTIONS': 3, 'FOOD#PRICES': 4, 'FOOD#QUALITY': 5, 'FOOD#STYLE_OPTIONS': 6, 'LOCATION#GENERAL': 7, 'RESTAURANT#GENERAL': 8, 'RESTAURANT#MISCELLANEOUS': 9, 'RESTAURANT#PRICES': 10, 'SERVICE#GENERAL': 11}\n",
            "Duygu Etiketleri: {'negative': 0, 'neutral': 1, 'positive': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Öznitelik Çıkarma.  \n",
        "  Burada metinleri, makine öğrenmesi algoritmalarının anlayabileceği bir şekile yani sayısal formata dönüştürecez. Bunun için TF-IDF tekniği kullanılmıştır. Bir kelimenin metin içinde ne sıklıkla geçtiğini ve bu kelimenin ne kadar ayırt edici olduğunu ölçen bir yöntemdir."
      ],
      "metadata": {
        "id": "gfOl4s1CXMvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF vektörleştirme\n",
        "vectorizer = TfidfVectorizer(max_features=50, stop_words=turkish_stop_words)\n",
        "X = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
        "\n",
        "# Hedef alan ve duygu etiketleri\n",
        "y_category = df['category_label']\n",
        "y_polarity = df['polarity_label']\n",
        "\n"
      ],
      "metadata": {
        "id": "gguCRlTTYmln"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Eğitimi.  \n",
        "  Hedef alanları ve duygu analizi için naive bayes modelini eğitelim"
      ],
      "metadata": {
        "id": "tSH3DlbRZlj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Eğitim ve test bölme\n",
        "X_train, X_test, y_category_train, y_category_test = train_test_split(X, y_category, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_polarity_train, y_polarity_test = train_test_split(X, y_polarity, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hedef alan modeli\n",
        "category_model = MultinomialNB()\n",
        "category_model.fit(X_train, y_category_train)\n",
        "y_category_pred = category_model.predict(X_test)\n",
        "\n",
        "# Duygu modeli\n",
        "polarity_model = MultinomialNB()\n",
        "polarity_model.fit(X_train, y_polarity_train)\n",
        "y_polarity_pred = polarity_model.predict(X_test)\n",
        "\n",
        "# Sonuçları değerlendirme\n",
        "print(\"Hedef Alan Modeli:\")\n",
        "print(classification_report(y_category_test, y_category_pred, target_names=le_category.classes_, zero_division=0))\n",
        "\n",
        "print(\"Duygu Modeli:\")\n",
        "print(classification_report(y_polarity_test, y_polarity_pred, target_names=le_polarity.classes_, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmf4QxDrZzrm",
        "outputId": "d813cdda-9834-417c-a2e3-d2c9fe4f094f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hedef Alan Modeli:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "        AMBIENCE#GENERAL       0.45      0.25      0.32        57\n",
            "           DRINKS#PRICES       0.00      0.00      0.00         3\n",
            "          DRINKS#QUALITY       0.00      0.00      0.00        15\n",
            "    DRINKS#STYLE_OPTIONS       0.00      0.00      0.00         7\n",
            "             FOOD#PRICES       1.00      0.33      0.50         3\n",
            "            FOOD#QUALITY       0.37      0.77      0.50        93\n",
            "      FOOD#STYLE_OPTIONS       0.00      0.00      0.00        23\n",
            "        LOCATION#GENERAL       0.00      0.00      0.00         7\n",
            "      RESTAURANT#GENERAL       0.23      0.28      0.25        43\n",
            "RESTAURANT#MISCELLANEOUS       0.00      0.00      0.00         1\n",
            "       RESTAURANT#PRICES       0.25      0.14      0.18         7\n",
            "         SERVICE#GENERAL       0.56      0.29      0.38        48\n",
            "\n",
            "                accuracy                           0.37       307\n",
            "               macro avg       0.24      0.17      0.18       307\n",
            "            weighted avg       0.33      0.37      0.32       307\n",
            "\n",
            "Duygu Modeli:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.37      0.48       115\n",
            "     neutral       1.00      0.04      0.08        25\n",
            "    positive       0.62      0.90      0.74       167\n",
            "\n",
            "    accuracy                           0.63       307\n",
            "   macro avg       0.76      0.44      0.43       307\n",
            "weighted avg       0.67      0.63      0.59       307\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Modeli Kullanalım.  \n",
        "  "
      ],
      "metadata": {
        "id": "jAO2ZXspdnOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yeni metin için tahmin\n",
        "new_text = [\"Fiyatlar çok fazla\"]\n",
        "new_text_cleaned = [clean_text(t) for t in new_text]\n",
        "new_X = vectorizer.transform(new_text_cleaned).toarray()\n",
        "\n",
        "# Tahminler\n",
        "category_prediction = le_category.inverse_transform(category_model.predict(new_X))\n",
        "polarity_prediction = le_polarity.inverse_transform(polarity_model.predict(new_X))\n",
        "\n",
        "print(\"Hedef Alan Tahmini:\", category_prediction)\n",
        "print(\"Duygu Tahmini:\", polarity_prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sZ8F4XYdyQ3",
        "outputId": "5818fdb0-f9d8-4ba8-ab77-2d0744b22211"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hedef Alan Tahmini: ['RESTAURANT#PRICES']\n",
            "Duygu Tahmini: ['negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performans Analizi\n",
        "Hedef alan modeli genel başarısı: %40. Hedefleri tespit etmede ortalama bir başarı göstermekte fakat bazı kategoriler için başarı olanı oldukça düşük. %77 ile recall değeri ile FOOD#QUALITY en doğru tahminde bulunan kategori olmuştur. Diğer kategorilerin değerleri oldukça düşüktür.  \n",
        "Duygu modeli genel başarısı: %63. Model duygu alanizi açısından daha iyi sonuç vermiştir. Pozitif ne negatif değerler kabul edilebilir bir başarı göstermiştir. Notr kısım ise çok düşük performans göstermektedir.  \n",
        "Bunların başlıca sebebi veri setinin yetersiz ve dengesiz olmasından kaynaklanmıştır. Daha fazla etiketlenmiş veri bularak yada, az olan kategorileri çıkarak yada naive bayes den daha karmaşık algoritmalar kullanarak (Random Forest, Logistic Regression, vb.) daha başarılı bir model eğitebiliriz.\n"
      ],
      "metadata": {
        "id": "Z8TwmAaJg-Qb"
      }
    }
  ]
}